version: "3.2"
services:
  # celery worker
  worker:
    container_name: celery_worker
    build:
      context: .
      dockerfile: docker/celery/Dockerfile
    volumes:
      - ./scripts:/app:cached
    command:
      [
        celery,
        worker,
        --app=worker.app,
        --pool=gevent,
        --concurrency=10,
        --loglevel=INFO,
      ]
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbit:5672
      - CELERY_BACKEND_URL=redis://redis:6379
      - TIKA_HOST=http://tika:4219
      - ES_HOSTS=http://elasticsearch:9200
      - ES_INDEX_DOCS=docs

  # message broker for celery
  rabbit:
    container_name: rabbit
    image: rabbitmq
    ports:
      - 5672:5672
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # cache service
  redis:
    container_name: redis
    build:
      context: ./docker/redis
    sysctls:
      - net.core.somaxconn=1024
    ports:
      - 6379:6379
    restart: always
    healthcheck:
      test: "curl --fail http://localhost:6379 || exit 1"
      interval: 10s
      timeout: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # file parsers by apache tika
  tika:
    container_name: tika
    build:
      context: ./fparse
    ports:
      - 4219:4219
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # message bus
  nats:
    image: nats:latest
    container_name: nats
    hostname: nats
    command: -DV
    ports:
      - 4222:4222
      - 6222:6222
      - 8222:8222
    restart: always
    healthcheck:
      test: "curl --fail http://localhost:4222 || exit 1"
      interval: 10s
      timeout: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # Amazon S3 compatible file store
  minio:
    image: minio/minio:latest
    container_name: minio
    volumes:
      - minio:/data
      - ./config/minio:/etc/minio:cached
    ports:
      - 9000:9000
    environment:
      MINIO_ACCESS_KEY: ${AWS_ACCESS_KEY_ID}
      MINIO_SECRET_KEY: ${AWS_SECRET_ACCESS_KEY}
    command: server --config-dir /etc/minio /data
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # image ops service (we need resizing at least)
  imageproxy:
    image: tianon/true
    # image: willnorris/imageproxy
    container_name: imageproxy
    # command: "-addr 0.0.0.0:1081"
    # ports:
    #   - 1081:1081
    # restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # dgraph cluster manager
  zero:
    image: tianon/true
    # image: dgraph/dgraph:v2.0.0-rc1
    container_name: zero
    volumes:
      - dgraph:/dgraph
    # ports:
    #   - 5080:5080
    #   - 6080:6080
    # command: dgraph zero --my=zero:5080
    # restart: always
    # healthcheck:
    #   test: "curl --fail --max-time 10 http://localhost:6080/health"
    #   interval: 10s
    #   timeout: 10s
    #   retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # dgraph node (GraphQL native database)
  dgraph:
    image: tianon/true
    # image: dgraph/dgraph:v2.0.0-rc1
    container_name: dgraph
    volumes:
      - dgraph:/dgraph
    # ports:
    #   - 8080:8080
    #   - 9080:9080
    # command: dgraph alpha --my=dgraph:7080 --zero=zero:5080 --lru_mb=2048 --auth_token=${DGRAPH_TOKEN} --whitelist=${DGRAPH_WHITELIST}
    # restart: always
    # healthcheck:
    #   test: "curl --fail --max-time 10 http://localhost:8080/health"
    #   interval: 10s
    #   timeout: 10s
    #   retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # dgraph UI
  ratel:
    image: tianon/true
    # image: dgraph/dgraph:v2.0.0-rc1
    container_name: ratel
    # ports:
    #   - 8000:8000
    # command: dgraph-ratel
    # restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # elasticsearch node1
  # see also https://github.com/deviantony/docker-elk
  # todo elasticsearch production config
  elasticsearch:
    build:
      context: ./
      dockerfile: ./docker/elasticsearch/Dockerfile
    container_name: elasticsearch
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata1:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    restart: always
    healthcheck:
      test: "curl --fail http://localhost:9200 || exit 1"
      interval: 10s
      timeout: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}
  # elasticsearch node2
  elasticsearch2:
    image: tianon/true
    # build:
    #   context: ./
    #   dockerfile: ./docker/elasticsearch/Dockerfile
    container_name: elasticsearch2
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata2:/usr/share/elasticsearch/data
    # restart: always
    # healthcheck:
    #   test: "curl --fail http://localhost:9300 || exit 1"
    #   interval: 10s
    #   timeout: 10s
    #   retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # lightweight UI for elasticsearch
  eshead:
    container_name: eshead
    image: mobz/elasticsearch-head:5-alpine
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # kibana - elasticsearch dashboard
  kibana:
    image: tianon/true
    # image: docker.elastic.co/kibana/kibana:7.6.1
    container_name: kibana
    environment:
      XPACK_MONITORING_ENABLED: "false"
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    volumes:
      - ./config/kibana/:/usr/share/kibana/config:cached
    # ports:
    #   - 5601:5601
    # restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # pyadmin API service
  pyadmin:
    depends_on:
      - app
    build:
      context: ./
      dockerfile: ./docker/pyadmin/Dockerfile
    container_name: pyadmin
    environment:
      HOSTNAME: ${HOSTNAME}
      HTTP_PORT: ${HTTP_PORT}
      HTTPS_PORT: ${HTTPS_PORT}
      DGRAPH_TOKEN: ${DGRAPH_TOKEN}
      JWT_SECRET: ${JWT_SECRET}
      SYSTEM_PWD: ${SYSTEM_PWD}
      ADMIN_PWD: ${ADMIN_PWD}
      # api key protection
      API_KEY_SECRET: ${API_KEY_SECRET}
      API_KEY: ${API_KEY}
      APP_ID: ${APP_ID}
      APP_SECRET: ${APP_SECRET}
      API_GATEWAY_URL: "http://app:4201"
      FLASK_ENV: development
      FLASK_PORT: 4211
    volumes:
      - ./scripts:/pyadmin:cached
      - ./schema.txt:/schema.txt:cached
      - ./docker/pyadmin/main.sh:/main.sh:cached
    ports:
      - 4211:4211
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # application API service
  app:
    depends_on:
      # - dgraph
      - minio
      - nats
    build:
      context: ./
      dockerfile: ./docker/app/Dockerfile
    container_name: app
    environment:
      HOSTNAME: ${HOSTNAME}
      HTTP_PORT: ${HTTP_PORT}
      HTTPS_PORT: ${HTTPS_PORT}
      DGRAPH_TOKEN: ${DGRAPH_TOKEN}
      JWT_SECRET: ${JWT_SECRET}
      SYSTEM_EMAIL: ${SYSTEM_EMAIL}
      SYSTEM_PWD: ${SYSTEM_PWD}
      ADMIN_EMAIL: ${ADMIN_EMAIL}
      ADMIN_PWD: ${ADMIN_PWD}
      # api key protection
      API_KEY_SECRET: ${API_KEY_SECRET}
      APP_ID: ${APP_ID}
      APP_SECRET: ${APP_SECRET}
      # aws services
      AWS_S3_ENDPOINT: ${AWS_S3_ENDPOINT}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      # oauth config
      FACEBOOK_KEY: ${FACEBOOK_KEY}
      FACEBOOK_SECRET: ${FACEBOOK_SECRET}
      VK_KEY: ${VK_KEY}
      VK_SECRET: ${VK_SECRET}
      GOOGLE_KEY: ${GOOGLE_KEY}
      GOOGLE_SECRET: ${GOOGLE_SECRET}
    volumes:
      - .:/pandora:cached
      - ./docker/app/main.sh:/main.sh:cached
    ports:
      - 4201:4201
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # event streaming service
  pubsub:
    depends_on:
      - nats
    build:
      context: ./
      dockerfile: ./docker/pubsub/Dockerfile
    container_name: pubsub
    environment:
      NATS_URI: ${NATS_URI}
    ports:
      - 4302:4302
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # web server - service gateway
  caddy:
    build:
      context: ./
      dockerfile: ./docker/caddy/Dockerfile
    container_name: caddy
    environment:
      CADDY_URLS: ${CADDY_URLS}
      HOSTNAME: ${HOSTNAME}
      HTTP_PORT: ${HTTP_PORT}
      HTTPS_PORT: ${HTTPS_PORT}
      DGRAPH_URL: http://dgraph:8080
      JWT_SECRET: ${JWT_SECRET}
      DGRAPH_TOKEN: ${DGRAPH_TOKEN}
      ADMIN_SECRET: ${ADMIN_SECRET}
      SYSTEM_PWD: ${SYSTEM_PWD}
      ADMIN_PWD: ${ADMIN_PWD}
      API_KEY: ${API_KEY}
      CADDYPATH: /data/caddy
    volumes:
      - caddy:/data/caddy
      - ./config/caddy/Caddyfile:/etc/Caddyfile:cached
    ports:
      - ${HTTP_PORT}:${HTTP_PORT}
      - ${HTTPS_PORT}:${HTTPS_PORT}
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

  # monitor
  autoheal:
    # image: willfarrell/autoheal
    image: tianon/true
    container_name: autoheal
    restart: on-failure
    # volumes:
    #   - /var/run/docker.sock:/var/run/docker.sock
    logging:
      driver: "json-file"
      options:
        max-size: ${LOG_MAX_SIZE}
        max-file: ${LOG_MAX_FILE}

volumes:
  minio:
  dgraph:
  caddy:
  esdata1:
  esdata2:
